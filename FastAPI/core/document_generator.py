from dotenv import load_dotenv
_ = load_dotenv()
import os
import json
import uuid
import traceback
import re

from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Annotated
from pydantic import BaseModel, Field
from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AnyMessage
from langgraph.graph.message import add_messages

from tavily import TavilyClient
from phoenix.otel import register
from opentelemetry.trace import StatusCode

from FastAPI.core.pdf_creator import save_to_pdf
from FastAPI.core.word_creator import save_to_word
from FastAPI.core.database_agent_3 import parts_summary, top_5_parts_by_price, top_5_part_distribution_by_country, parts_average_price, total_component_price
from FastAPI.core.CoT_prompting import COT_EXAMPLES

from FastAPI.automotive_simulation.simulation import analyze_tariff_impact
from FastAPI.core.utils import summarize_simulation_content, convert_numpy, serialize_state
from langchain.agents import tool

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
CHARTS_DIR = os.path.join(PROJECT_ROOT, "FastAPI", "core", "charts")
REPORTS_DIR = os.path.join(PROJECT_ROOT, "FastAPI", "reports_and_graphs")
os.makedirs(CHARTS_DIR, exist_ok=True)
os.makedirs(REPORTS_DIR, exist_ok=True)

load_dotenv()
pheonix_key = os.getenv("PHOENIX_API_KEY")
pheonix_collector_endpoint = os.getenv("PHOENIX_COLLECTOR_ENDPOINT")

# configure the Phoenix tracer
tracer_provider = register(
  project_name="my-llm-app", # Default is 'default'
  auto_instrument=True, # See 'Trace all calls made to a library' below
)
tracer = tracer_provider.get_tracer(__name__)

# setup inmemory sqlite checkpointers
import sqlite3
from langgraph.checkpoint.sqlite import SqliteSaver

conn = sqlite3.connect(":memory:", check_same_thread=False)
memory = SqliteSaver(conn)

# keeping
class AgentState(TypedDict):
    # human input
    task: str
    # plan the planning agent will generate
    plan: str
    # draft of the report
    draft: str
    # critique agent will populate this key
    critique: str
    # documents tavily has come back with
    web_content: List[str]
    # information from the database
    db_content: Annotated[List[AnyMessage], add_messages]
    db_summary: str
    trajectory: List[str]
    # information from running the simulation
    simulation_content: dict
    # path to the chart generated by the database_plan_node
    chart_metadata: List[Dict[str, str]]
    # keep track of how many times we've gone through the loop
    revision_number: int
    max_revisions: int
    # chart generation
    chart_plan: List[Dict[str, str]]
    current_chart_index: int
    chart_code: str
    chart_generation_success: bool
    chart_generation_error: str
    chart_retry_count: int
    max_chart_retries: int
    articles_path: str
    parts_path: str

from langchain_openai import ChatOpenAI
# creating model
# temperature of 0 will make it very deterministic
model = ChatOpenAI(model="gpt-4o", temperature=0)

# prompt for llm that is going to write out the plan for the essay
PLAN_PROMPT = f"""You are an expert research analyst tasked with writing a high level outline of an automotive supply \
chain report. Write such an outline for the user provided topic using the sections below. Give an \
outline of the essay along with any relevant notes or instructions for the sections. 

    1. Executive Summary
    2. Introduction
    3. Overview of the braking system component
    4. Supply chain structure
    5. Tariff simulation scenarios
    6. Risk Assessment
    7. Conclusion and Recommendations
    8. References
    9. Appendices

Here are reasoning examples to guide your thought process:
{COT_EXAMPLES}

"""

# writing the essay given the information that was researched
WRITER_PROMPT = f"""You are a research analyst tasked with writing a report of at least 800 words with a maximum of \
1000 word report. \

Here are reasoning examples you should follow:
{COT_EXAMPLES}

Before writing, think step-by-step: \
1. Summarize insights from each source (database, web, simulation). \
2. Plan the structure and flow of arguments. \
3. Write the full report based on your reasoning. \

Generate the best report possible for the user's request and the initial outline. Making sure to include any \
charts available in the body of the report in their relevant sections. If the user provides critique, respond with a \
revised version of your previous attempts. Provide the output in a JSON format using the structure below. \

{{
      "title": "<Report Title>",
      "sections": [
        {{
          "heading": "<Section Heading>",
          "content": "<Plain text or markdown content>",
          "subsections": [
            {{
              "heading": "<Subsection Heading>",
              "content": "<Plain text or markdown content>"
            }}
          ]
        }}
      ]
    }}
    
The charts should be included using placeholders like [[FIGURE:<chart_id>]] in part of the report where the chart \
should appear. These placeholders will be replaced with the actual figures in the final report. On revision don't \
remove any graphs.

Please can you reference all external sources using Harvard referencing style. 

Only include sections and subsections in the report. Do not include subsubsections or any headings nested deeper \
than two levels.

If the task asks for information about tariff impacts then make sure to call the automotive_tariff_simulation tool. \
Please include all charts generated from the tool call in the report in the tariff simulation section without \
splitting them into sub sections. Don't include any other charts in the tariff simulation section. 

Utilize all the information below as needed: 



------

"""

# control how we are critiqing the draft of the essay
REFLECTION_PROMPT = """You are a manager reviewing the analysts report. \
Generate critique and recommendations for the analysts submission. \
Provide detailed recommendations, including requests for length, depth, style, etc."""

DATABASE_PLAN_INSTRUCTIONS = """ You are a supply chain data analyst with access to several \
database tools. Your role is to extract relevant automotive part insights that will inform a \
detailed written report. Do not hallucinate numbers. Only use tool outputs. Pick tools one at a time, \
picking the most appropriate tool.
"""

# given a plan will generate a bunch of queries and pass to tavily
RESEARCH_PLAN_PROMPT = """You are a researcher charged with providing information that can \
be used when writing the following essay. Generate a list of search queries that will gather \
any relevant information. Only generate 3 queries max."""

# after we've made the critique will pass the list of queries to pass to tavily
RESEARCH_CRITIQUE_PROMPT = """You are a researcher charged with providing information that can \
be used when making any requested revisions (as outlined below). \
Generate a list of search queries that will gather any relevant information. Only generate 3 queries max."""

# for generating a list of queries to pass to tavily will use function calling so we get a list of strings
# from tavily

class ResearchQueries(BaseModel):
    queries: List[str]

class DBQueries(BaseModel):
    queries: List[str]

# importing taviliy as using it in a slightly unconventional way
tavily = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

class simulation_inputs(BaseModel):
    target_country: str = Field(..., description="Country to simulate tariff shock for")
    tariff_rates: List[int] = Field(description="tariff rates to use in the tariff shock simulation.")

@tool(args_schema=simulation_inputs)
def automotive_tariff_simulation(target_country: str, tariff_rates: List[float]) -> dict:
    """
    Run an automotive simulation on the component/vehicle showing the impact of tariff shocks of a certain country
    on the component/vehicle.

    Accepts either decimals (e.g., 0.1 for 10%) or integers (e.g., 10 for 10%) and normalizes all to decimals.
    """
    # Normalize rates: if any rate > 1, treat it as a percentage (e.g., 10 becomes 0.10)
    normalized_rates = [
        r / 100 if r > 1 else r
        for r in tariff_rates
    ]

    response = analyze_tariff_impact(target_country, normalized_rates)
    return convert_numpy(response)

# take in the state and create list of messages, one of them is going to be the planning prompt
# then create a human message which is what we want system to do
@tracer.chain
def plan_node(state: AgentState):
    messages = [
        SystemMessage(content=PLAN_PROMPT),
        HumanMessage(content=state['task'])
    ]
    # pass these messages to the model
    response = model.invoke(messages)
    # get the content of the messages and pass to the plan key
    return {"plan": response.content}


tools = [
    parts_summary,
    top_5_parts_by_price,
    top_5_part_distribution_by_country,
    parts_average_price,
    total_component_price
]

db_model = ChatOpenAI(
    model="gpt-4o",
    temperature=0
).bind_tools(tools)

tools_by_name = {tool.name: tool for tool in tools}

# --- Tool Node ---
@tracer.chain
def tool_node(state: AgentState):
    outputs = []
    last_message = state["db_content"][-1]
    for tool_call in last_message.tool_calls:
        tool_name = tool_call["name"]
        args = dict(tool_call["args"])
        # Inject paths
        args["articles_path"] = state["articles_path"]
        args["parts_path"] = state["parts_path"]

        if tool_name not in tools_by_name:
            result = "Unknown tool, please retry."
        else:
            result = tools_by_name[tool_name].invoke(args)

        outputs.append(ToolMessage(
            content=json.dumps(result),
            name=tool_name,
            tool_call_id=tool_call["id"]
        ))
    return {"db_content": state["db_content"] + outputs}

# --- Model Node ---
@tracer.chain
def call_model(state: AgentState, config=None):
    system_prompt = SystemMessage(content=f"""
You are a database assistant helping with the drafting of an automotive supply chain report. Use the available tools 
to retrieve the relevant data for the report.
The file paths required by the tools are available from state:
- articles_path - path to the articles CSV file
- parts_path - path to the parts CSV file

Just return a summary of the raw data from the tools.

See the following report plan to guide you what data to extract:
{state.get('plan', 'No plan provided')}
""")
    response = db_model.invoke([system_prompt] + state["db_content"], config)
    return {"db_content": state["db_content"] + [response]}

@tracer.chain
def summarize_db_node(state: AgentState):
    db_content_text = "\n\n".join(str(msg.content) for msg in state.get("db_content", []))
    response = model.invoke([
        SystemMessage(content="Analyse the data from the database agent and provide additional insight. "
                              "Be succinct, don't speculate, only use the information provided and make the "
                              "analysis quantative:"),
        HumanMessage(content=db_content_text)
    ])

    return {
        "db_summary": response.content
    }

# takes in the plan and does some research
@tracer.chain
def research_plan_node(state: AgentState):
    # response with what we will invoke this with is the
    # response will be pydantic model which has the list of queries
    queries = model.with_structured_output(ResearchQueries).invoke([
        # researching planning prompt and planning prompt
        SystemMessage(content=RESEARCH_PLAN_PROMPT),
        HumanMessage(content=state['task'])
    ])
    # original content
    content = state['web_content'] or []
    # loop over the queries and search for them in Tavily
    for q in queries.queries:
        with tracer.start_as_current_span(
                "TavilySearch",
                openinference_span_kind="tool",
                attributes={"query": q}
        ) as span:
            span.set_input(value=q)
            response = tavily.search(query=q, max_results=2)
            span.set_output(value=response)
            for r in response['results']:
                # get the list of results and append them to the content
                content.append(f"Source: {r['url']}\n{r['content']}")
    # return the content key which is equal to the original content plus the accumulated content
    return {"web_content": content}

model_with_tools = model.bind_tools([automotive_tariff_simulation])

@tracer.chain
def chart_planning_node(state: AgentState):
    """
    Decides what charts to generate based on DB summary & content.
    Returns `chart_plan` for the next node to consume.
    """
    db_summary = state.get("db_summary", "")
    db_content = "\n\n".join(str(msg.content) for msg in state.get("db_content", []))

    prompt = f"""
You are a supply chain data visualization expert. 
Based on the following database summary and raw data, propose 1 (maybe 2) meaningful charts 
for an automotive braking system supply chain report.

Database summary:
{db_summary}

Structured data:
{db_content}

Return JSON list like:
[
  {{ "chart_id": "chart1", "chart_description": "Top 5 parts by price" }},
  {{ "chart_id": "chart2", "chart_description": "Country of origin distribution" }}
]
"""

    response = model.invoke([SystemMessage(content=prompt)])
    try:
        chart_plan = json.loads(response.content)
        if not isinstance(chart_plan, list):
            chart_plan = [chart_plan]
    except json.JSONDecodeError:
        chart_plan = [{"chart_id": "chart1", "chart_description": response.content.strip()}]

    return {"chart_plan": chart_plan}

@tracer.chain
def generate_chart_code_node(state: AgentState):

    # Determine which chart we are working on
    chart_index = state.get("current_chart_index", 0)
    chart_plan = state.get("chart_plan", [])

    if chart_index >= len(chart_plan):
        # No charts left to process
        return {"chart_code": "", "chart_generation_success": True}

    chart = chart_plan[chart_index]
    chart_description = chart.get("chart_description", "No description")

    prompt = f"""You are a data visualization expert. 
Generate a Python script using matplotlib to produce the chart described. 
Always save with: `plt.savefig(chart_path)` and never assign `chart_path` inside the script.
Assume it is already defined.

When designing the chart use professional styling ideally using blue.

Data:
{state['db_content']}

Chart requirement:
{chart_description}
"""

    response = model.invoke([SystemMessage(content=prompt)])
    match = re.search(r"```(?:python)?\n(.*?)```", response.content, re.DOTALL)
    chart_code = match.group(1).strip() if match else response.content.strip()

    return {"chart_code": chart_code}

@tracer.chain
def execute_chart_code_node(state: AgentState):
    try:
        code = state["chart_code"]

        # Get chart info
        chart_index = state.get("current_chart_index", 0)
        chart_plan = state.get("chart_plan", [])
        chart_id = chart_plan[chart_index]["chart_id"] if chart_index < len(chart_plan) else f"chart_{chart_index}"

        chart_path = os.path.join(CHARTS_DIR, f"{chart_id}_{uuid.uuid4().hex}.png")
        exec_globals = {"__file__": chart_path, "chart_path": chart_path}
        exec(code, exec_globals)

        # Append to chart_metadata
        chart_metadata = state.get("chart_metadata", [])
        chart_metadata.append({"id": chart_id, "path": chart_path})

        return {
            "chart_metadata": chart_metadata,
            "chart_generation_success": True,
            "current_chart_index": chart_index + 1,
            "chart_retry_count": 0
        }
    except Exception as e:
        return {
            "chart_generation_success": False,
            "chart_generation_error": traceback.format_exc(),
            "chart_code": state["chart_code"]
        }


@tracer.chain
def reflect_chart_node(state: AgentState):
    # If previous execution failed → fix code
    if not state.get("chart_generation_success", False):
        error = state.get("chart_generation_error", "")
        previous_code = state.get("chart_code", "")

        prompt = f"""The previous chart code failed with this error:
{error}

Here is the failed code:
{previous_code}

Please revise the code so it avoids the error and still meets the requirements.
"""
        response = model.invoke([SystemMessage(content=prompt)])
        return {
            "chart_code": response.content,
            "chart_retry_count": state.get("chart_retry_count", 0) + 1,
            "chart_generation_success": False,
            "chart_generation_error": ""
        }

    # If successful (but still more charts), just continue
    return {}

@tracer.chain
def generation_node(state: AgentState):
    db = state.get("db_summary", "")
    web = "\n\n".join(state.get("web_content", []))
    chart_metadata = state.get("chart_metadata", [])
    simulation_content = state.get("simulation_content")
    charts = "\n\n".join(
        [f"Include these charts in the report: \n[[FIGURE:{item['id']}]]" for item in chart_metadata])

    if simulation_content:
        simulation_content_summary = summarize_simulation_content(simulation_content)
        messages = [
            SystemMessage(content=WRITER_PROMPT),
            HumanMessage(content=f"Task:\n{state['task']}"),
            HumanMessage(content=f"Plan:\n{state['plan']}"),
            HumanMessage(content=f"Database Insights:\n{db}"),
            HumanMessage(content=f"Web Research:\n{web}"),
            HumanMessage(content=f"Charts:\n{charts}"),
            HumanMessage(content=f"Simulation Results:\n{simulation_content_summary}")
        ]

        print("Skipping automotive_tariff_simulation tool — already cached.")
        initial_response = model.invoke(messages)

        return {
            "draft": initial_response.content,
            "chart_metadata": chart_metadata,
            "simulation_content": simulation_content,
            "revision_number": state.get("revision_number", 1) + 1
        }

    messages = [
        SystemMessage(content=WRITER_PROMPT),
        HumanMessage(content=f"Task:\n{state['task']}"),
        HumanMessage(content=f"Plan:\n{state['plan']}"),
        HumanMessage(content=f"Database Insights:\n{db}"),
        HumanMessage(content=f"Web Research:\n{web}"),
        HumanMessage(content=f"Charts:\n{charts}")
    ]
    initial_response = model_with_tools.invoke(messages)

    # Step 2: If tool was called, run it and return tool result to model
    if hasattr(initial_response, "tool_calls") and initial_response.tool_calls:
        tool_call = initial_response.tool_calls[0]
        tool_name = tool_call["name"]
        args = tool_call["args"]
        tool_call_id = tool_call["id"]

        # Dispatch map for tools
        available_tools = {
            "automotive_tariff_simulation": automotive_tariff_simulation
        }

        tool_fn = available_tools.get(tool_name)
        if not tool_fn:
            raise ValueError(f"Unknown tool called: {tool_name}")

        tool_output = tool_fn.invoke(args)

        simulation_content = tool_output
        simulation_content_summary = summarize_simulation_content(tool_output)

        messages = [
            SystemMessage(content=WRITER_PROMPT),
            HumanMessage(content=f"Task:\n{state['task']}"),
            HumanMessage(content=f"Plan:\n{state['plan']}"),
            HumanMessage(content=f"Database Insights:\n{db}"),
            HumanMessage(content=f"Web Research:\n{web}"),
            HumanMessage(content=f"Charts:\n{charts}"),
            HumanMessage(content=f"Simulation Results:\n{simulation_content_summary}"),
            initial_response,
            ToolMessage(tool_call_id=tool_call_id, content=json.dumps(tool_output))
        ]
        follow_up = model_with_tools.invoke(messages)
        content = follow_up.content

        # Add chart metadata if available
        if "output_files" in tool_output and tool_output["output_files"].get("charts_saved"):
            chart_paths = tool_output["output_files"].get("chart_paths", {})
            for chart_id, chart_path in chart_paths.items():
                chart_metadata.append({
                    "id": os.path.splitext(os.path.basename(chart_path))[0],
                    "path": chart_path
                })

    else:
        content = initial_response.content

    return {
        "draft": content,
        "chart_metadata": chart_metadata,
        "simulation_content": simulation_content,
        "revision_number": state.get("revision_number", 1) + 1
    }

@tracer.chain
def reflection_node(state: AgentState):
    messages = [
        # take the reflection node and the draft
        SystemMessage(content=REFLECTION_PROMPT),
        HumanMessage(content=state['draft'])
    ]
    response = model.invoke(messages)
    # going to generate the critique
    return {"critique": response.content}

@tracer.chain
def research_critique_node(state: AgentState):
    queries = model.with_structured_output(ResearchQueries).invoke([
        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),
        HumanMessage(content=state['critique'])
    ])
    # get the original content and append with new queries
    content = state['web_content'] or []
    for q in queries.queries:
        with tracer.start_as_current_span(
                "TavilySearch",
                openinference_span_kind="tool",
                attributes={"query": q}
        ) as span:
            span.set_input(value=q)
            response = tavily.search(query=q, max_results=2)
            span.set_output(value=response)
            for r in response['results']:
                content.append(r['content'])
    return {"web_content": content}

# look at the revision number - if greater than the max revisions will then end.
def should_continue(state):
    with tracer.start_as_current_span(
            "ShouldContinueCheck",
            openinference_span_kind="chain"
    ) as span:
        span.set_input(value=state)
        if state["revision_number"] > state["max_revisions"]:
            print(save_to_pdf(content=state["draft"], filename="report.pdf", chart_metadata=state.get("chart_metadata", [])))
            print(save_to_word(content=state["draft"], filename="report.docx", chart_metadata=state.get("chart_metadata", [])))
            result = END
        else:
            result = "reflect"
        span.set_output(value=result)
        return result

def execute_chart_next_node(state: AgentState) -> str:
    if state.get("chart_generation_success", False):
        # Was successful – check if more charts left
        if state.get("current_chart_index", 0) >= len(state.get("chart_plan", [])):
            return "research_plan"
        else:
            return "reflect_chart"
    else:
        # Failed, need to reflect
        return "reflect_chart"

def db_should_continue(state: AgentState):
    last_message = state["db_content"][-1]
    return "continue" if last_message.tool_calls else "end"

# initialise the graph with the agent state
builder = StateGraph(AgentState)

# add all nodes
builder.add_node("planner", plan_node)
builder.add_node("generate", generation_node)
builder.add_node("reflect", reflection_node)
builder.add_node("research_plan", research_plan_node)
builder.add_node("db_agent", call_model)
builder.add_node("db_tools", tool_node)
builder.add_node("summarize_db", summarize_db_node)
builder.add_node("chart_planning_node", chart_planning_node)
builder.add_node("generate_chart_code", generate_chart_code_node)
builder.add_node("execute_chart_code", execute_chart_code_node)
builder.add_node("reflect_chart", reflect_chart_node)
builder.add_node("research_critique", research_critique_node)

# set entry point
builder.set_entry_point("planner")

# add conditional edge
builder.add_conditional_edges(
    "generate",
    should_continue,
    {END: END, "reflect": "reflect"}
)

# add in basic edges
builder.add_edge("planner", "db_agent")
builder.add_edge("summarize_db", "chart_planning_node")
builder.add_edge("chart_planning_node", "generate_chart_code")
builder.add_edge("generate_chart_code", "execute_chart_code")
builder.add_conditional_edges(
    "execute_chart_code",
    execute_chart_next_node,
    {
        "reflect_chart": "reflect_chart",
        "research_plan": "research_plan"
    }
)

builder.add_conditional_edges("db_agent", db_should_continue, {"continue": "db_tools", "end": "summarize_db"})
builder.add_edge("db_tools", "db_agent")

builder.add_edge("reflect_chart", "generate_chart_code")
builder.add_edge("research_plan", "generate")

builder.add_edge("reflect", "research_critique")
builder.add_edge("research_critique", "generate")

# compile graph and add in checkpointer
graph = builder.compile(checkpointer=memory)

# from IPython.display import Image
#
# Image(graph.get_graph().draw_png())

# save the graph
output_graph_path = "langgraph.png"
with open(output_graph_path, "wb") as f:
    f.write(graph.get_graph().draw_mermaid_png())


def run_agent(messages, parts_path, articles_path):
    with (tracer.start_as_current_span(
            "LangGraphExecution",
            openinference_span_kind="chain")
    as span):
        span.set_input(value=messages)

        final_state = {}

        # adding in graph.stream so can see all the steps
        thread = {"configurable": {"thread_id": "1"}}
        for s in graph.stream({
            'task': messages,
            'max_revisions': 2,
            'revision_number': 1,
            'db_content': [],
            'web_content': [],
            'simulation_content': {},
            'chart_metadata': [],
            'plan': '',
            'draft': '',
            'critique': '',
            'chart_code': '',
            'chart_generation_success': False,
            'chart_generation_error': '',
            'chart_retry_count': 0,
            'max_chart_retries': 2,
            'chart_plan': [],
            'current_chart_index': 0,
            'articles_path': articles_path,
            'parts_path': parts_path
        }, thread):
            print(s)

            final_state = s

        BASE_DIR = os.path.dirname(os.path.abspath(__file__))
        SAVE_PATH = os.path.join(BASE_DIR, "streamlit_data/ai_supplychain_state.json")

        with open(SAVE_PATH, "w") as f:
            json.dump(serialize_state(final_state), f, indent=2)

        span.set_status(StatusCode.OK)


# start from the outermost layer and work your way down so you capture the right info
# only just calling this run_agent span and calls to add tracing
def start_main_span(messages, parts_path, articles_path):
    print("Starting main span with messages:", messages)

    # span_kind maps to colors etc...
    # anything in the with cause block will be treated as part of that span
    with tracer.start_as_current_span(
            "AgentRun", openinference_span_kind="agent"
    ) as span:
        # setting the input
        span.set_input(value=messages)
        ret = run_agent(messages, parts_path, articles_path)
        print("Main span completed with return value:", ret)
        # setting the output
        span.set_output(value=ret)
        # set status call - called correctly
        span.set_status(StatusCode.OK)
        return ret

def auto_supplychain_prompt_template(manufacturer, model, component, country, rates):
    rates_str = ", ".join(f"{r}%" for r in rates)
    return (
        f"Write me a report on the supply chain of the {manufacturer} {model} {component}. Including a "
        f"tariff shock simulation for {country} with rates of {rates_str}."
    )

prompt = auto_supplychain_prompt_template(
    manufacturer="Toyota",
    model="RAV4",
    component="braking system",
    country="Japan",
    rates=[20, 50, 80]
)

if __name__ == "__main__":
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    parts_path = os.path.join(BASE_DIR, "Toyota_RAV4_brake_dummy_data/RAV4_brake_parts_data.csv")
    articles_path = os.path.join(BASE_DIR, "Toyota_RAV4_brake_dummy_data/RAV4_brake_articles_data.csv")

    print(prompt)
    start_main_span(prompt, parts_path, articles_path)
